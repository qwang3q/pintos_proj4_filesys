+-------------------------+
|      CS 5600            |
| PROJECT 4: FILE SYSTEMS |
|     DESIGN DOCUMENT     |
+-------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Qian Wang <wang.qian4@husky.neu.edu>
Cong Niu  <niu.co@husky.neu.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.
We are a team of 2, as discussed and agreed with professor, we don't need to implement "SUBDIRECTORIES"

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

INDEXED AND EXTENSIBLE FILES
============================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* 
    changed. Instead of using single pointer to first sector,
    use 124 pointers for direct block, and 128 pointers for indirect blocks
*/
struct inode_disk
  {
    /* First data sector. */
    block_sector_t direct_blocks[DIRECT_BLOCK_COUNT];
    block_sector_t indirect;            // indirect blocks
    block_sector_t d_indirect;          // double indirect blocks

    off_t length;                       /* File size in bytes. */
    unsigned magic;                     /* Magic number. */
    //uint32_t unused[125];               /* Not used. */
  };

/*
    data structure holding pointers to either indirect block or data block
*/
struct indirect_block
    {
        block_sector_t blocks[INDIRECT_BLOCK_COUNT];
    };

>> A2: What is the maximum size of a file supported by your inode
>> structure?  Show your work.
A single inode has pointers to following sectors:
- direct blocks: 124
- indirect blocks: 128
- double indirect blocks: 128 * 128
So, in total there are 124 + 128 + 128 * 128 = 16636 blocks
    in total there are 16636 * 512 = 8517632 bytes, which is 8.12Mb

---- SYNCHRONIZATION ----

>> A3: Explain how your code avoids a race if two processes attempt to
>> extend a file at the same time.
A lock is defined to ensure two processes cannot extend a file at the same time.
The length of file is only determined after acquiring the lock, so 
the information is always accurate.

>> A4: Suppose processes A and B both have file F open, both
>> positioned at end-of-file.  If A reads and B writes F at the same
>> time, A may read all, part, or none of what B writes.  However, A
>> may not read data other than what B writes, e.g. if B writes
>> nonzero data, A is not allowed to see all zeros.  Explain how your
>> code avoids this race.
Because readers and writers don't block each other, they can access the file
at the same time. So A would keep on reading while B is writing, and 

TODO


>> A5: Explain how your synchronization design provides "fairness".
>> File access is "fair" if readers cannot indefinitely block writers
>> or vice versa.  That is, many processes reading from a file cannot
>> prevent forever another process from writing the file, and many
>> processes writing to a file cannot prevent another process forever
>> from reading the file.
Readers don't acqire lock at all, and as a result, readers won't block
writers indefinitely. On the other hand, writers don't block readers either,
so the system is relatively fair.

---- RATIONALE ----

>> A6: Is your inode structure a multilevel index?  If so, why did you
>> choose this particular combination of direct, indirect, and doubly
>> indirect blocks?  If not, why did you choose an alternative inode
>> structure, and what advantages and disadvantages does your
>> structure have, compared to a multilevel index?
- Our inode structure is multilevel index as described in course material.
In the original implementation, there is only a single pointer pointing at
the first sector and assume all sectors following. This implementation
wasted 125 pointers, so in our implementation it's pretty natural to have
124 blocks of direct sectors.
- For indirect blocks, it's a tree structure, the leaves are data blocks,
and all nodes in between are just arrays of pointers pointing at
blocks on next level.
- For choosing data structure representing blocks, there were initially 
2 ideas, the first one was linked list representation, and second one was
arrays. We adopted the second one, as it's more efficiently looking up.

SUBDIRECTORIES
==============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
N/A
---- ALGORITHMS ----

>> B2: Describe your code for traversing a user-specified path.  How
>> do traversals of absolute and relative paths differ?
N/A
---- SYNCHRONIZATION ----

>> B4: How do you prevent races on directory entries?  For example,
>> only one of two simultaneous attempts to remove a single file
>> should succeed, as should only one of two simultaneous attempts to
>> create a file with the same name, and so on.
N/A
>> B5: Does your implementation allow a directory to be removed if it
>> is open by a process or if it is in use as a process's current
>> working directory?  If so, what happens to that process's future
>> file system operations?  If not, how do you prevent it?
N/A
---- RATIONALE ----

>> B6: Explain why you chose to represent the current directory of a
>> process the way you did.
N/A
BUFFER CACHE
============

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* 
    struct holds all information of cached block in memory 
*/
struct cache_block {
    uint8_t block[BLOCK_SECTOR_SIZE];
    block_sector_t disk_sector;

    bool free;
    int c_in_use;
    bool accessed;
    bool dirty;
};

---- ALGORITHMS ----

>> C2: Describe how your cache replacement algorithm chooses a cache
>> block to evict.
Our design adopted clock evicting algorithm, which is basically keeping
a handle scaning all cache blocks, and:
- skip blocks that are being used at the moment
- give recently accessed blocks a second chance
- evicting if none of the above is true

>> C3: Describe your implementation of write-behind.
Implemented a cache_flush function, which scans all cache blocks, write 
write dirty blocks back to disk and mark them clean.
This function is utilized by filesys_done, and also called by a periodically
running job to perform write-behind.

>> C4: Describe your implementation of read-ahead.
TODO

---- SYNCHRONIZATION ----

>> C5: When one process is actively reading or writing data in a
>> buffer cache block, how are other processes prevented from evicting
>> that block?
There is a field in cache_block that keeps track of c_in_use, which is 
count of times the file is currently in use, and the evicting logic would
consider this block in use if c_in_use is greater than 0. Thus as long as
thre is one process still actively reading or writing in this block, the
block is not evicted.

>> C6: During the eviction of a block from the cache, how are other
>> processes prevented from attempting to access the block?
There is a lock defined specifically for this purpose. The access of
a cached block is strictly protected by this lock, including evicting.
So other processes have to wait until the eviction is completed before
accessing the cached block.

---- RATIONALE ----

>> C7: Describe a file workload likely to benefit from buffer caching,
>> and workloads likely to benefit from read-ahead and write-behind.
Any workload that reads same disk areas frequently would benefit
from buffer caching.

For read-ahead, if a process is reading a large file consecutively, 
the cache hit rate is going to be approaching 100%, as only the first 
block is missed. So the performance would be extremely good.

For write-behind, if a process, or multiple processes simultaneously
writing random parts of a file, hold them in memory is going to be 
greatly performant, and writing all to disk at once is also beneficial.

